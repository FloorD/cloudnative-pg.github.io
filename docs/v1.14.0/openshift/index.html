<!DOCTYPE html>




<html lang="en">

<head>
  <title>CloudNative PG</title>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <meta name="description" content="CloudNativePG is the Kubernetes operator that covers the full lifecycle of a highly available PostgreSQL database cluster with a primary/standby architecture, using native streaming replication." />
  <meta name="keywords" content="" />
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet" />
  <link href="/main.min.css" rel="stylesheet" />
  <link rel="favicon" href="/favicon/favicon.ico">
</head>

<body>
  <div class="h-screen w-screen">
    
<main>
  <header>
    <div class="flex flex-row px-16 justify-between py-5">
      <div>
        
        <a href="/"><img src="/logo/large_logo.svg" class="h-14" alt="Cloud Native Postgres Logo"></a>
      </div>
      <div>
        <ul class="flex gap-14 text-2xl text-slate-400 my-5">
          <li><a href="/docs/1.15.0/" target="_blank">Documentation</a></li>
          <li>Support</li>
          <li>End users</li>
          <li>Blog</li>
        </ul>
      </div>
      <div class="flex gap-5 my-4">
        <a href="https://github.com/cloudnative-pg/cloudnative-pg">
          <img src="/icons/Git.svg" alt="Github">
        </a>
        <a href="https://cloudnativepg.slack.com/">
          <img src="/icons/Slack.svg" alt="Slack">
        </a>
        <a href="https://twitter.com/CloudNativePg">
          <img src="/icons/Twitter.svg" alt="Twitter">
        </a>
        <a href="https://www.youtube.com/channel/UCTGH88W1BiuRRPTzJUDPJyA">
          <img src="/icons/YouTube.svg" alt="YouTube">
        </a>
      </div>
    </div>
  </header>
</main>


    
<h2 class="text-2xl"></h2>
<h1 id="red-hat-openshift">Red Hat OpenShift</h1>
<p>Cloud Native PostgreSQL is certified to run on
<a href="https://www.openshift.com/products/container-platform">Red Hat OpenShift Container Platform (OCP) version 4.x</a>
and is available directly from the
<a href="https://catalog.redhat.com/software/operators/detail/5fb41c88abd2a6f7dbe1b37b">Red Hat Catalog</a>.</p>
<p>The goal of this section is to help you decide the best installation method for
Cloud Native PostgreSQL based on your organizations&rsquo; security and access
control policies.</p>
<p>Cloud Native PostgreSQL can be installed and managed via:</p>
<ul>
<li><a href="#installation-via-web-console">OpenShift web console</a></li>
<li><a href="#installation-via-the-oc-cli">OpenShift command-line interface (CLI)</a> called <code>oc</code>, for full control</li>
</ul>
<p>Cloud Native PostgreSQL supports all available install modes defined by
OpenShift:</p>
<ul>
<li>cluster-wide, in all namespaces</li>
<li>local, in a single namespace</li>
<li>local, watching multiple namespaces (only available using <code>oc</code>)</li>
</ul>
<p>!!! Note
A project is a Kubernetes namespace with additional annotations, and is the
central vehicle by which access to resources for regular users is managed.</p>
<p>In most cases, the default cluster-wide installation of Cloud Native PostgreSQL
is the recommended one, with either central management of PostgreSQL clusters
or delegated management (limited to specific users/projects according to RBAC
definitions - see <a href="#important-openshift-concepts">&ldquo;Important OpenShift concepts&rdquo;</a>
and <a href="#users-and-permissions">&ldquo;Users and Permissions&rdquo;</a> below).</p>
<p>!!! Important
Both the installation and upgrade processes require access to an OpenShift
Container Platform cluster using an account with <code>cluster-admin</code> permissions.
From <a href="https://docs.openshift.com/container-platform/4.9/authentication/using-rbac.html#default-roles_using-rbac">&ldquo;Default cluster roles&rdquo;</a>,
a <code>cluster-admin</code> is <em>&ldquo;a super-user that can perform any action in any
project. When bound to a user with a local binding, they have full control over
quota and every action on every resource in the project</em>&rdquo;.</p>
<h2 id="important-openshift-concepts">Important OpenShift concepts</h2>
<p>To understand how the Cloud Native PostgreSQL operator fits in an OpenShift environment,
you must familiarize yourself with the following Kubernetes-related topics:</p>
<ul>
<li>Operators</li>
<li>Authentication</li>
<li>Authorization via Role-based Access Control (RBAC)</li>
<li>Service Accounts and Users</li>
<li>Rules, Roles and Bindings</li>
<li>Cluster RBAC vs local RBAC through projects</li>
</ul>
<p>This is especially true in case you are not comfortable with the elevated
permissions required by the default cluster-wide installation of the operator.</p>
<p>We have also selected the diagram below from the OpenShift documentation, as it
clearly illustrates the relationships between cluster roles, local roles,
cluster role bindings, local role bindings, users, groups and service accounts.</p>
<p><img src="./images/openshift/openshift-rbac.png" alt="OpenShift Cluster Roles">
The <a href="#predefined-rbac-objects">&ldquo;Predefined RBAC objects&rdquo; section</a>
below contains important information about how Cloud Native PostgreSQL adheres
to Kubernetes and OpenShift RBAC implementation, covering default installed
cluster roles, roles, service accounts.</p>
<p>If you are familiar with the above concepts, you can proceed directly to the
selected installation method.  Otherwise, we recommend that you read the
following resources taken from the OpenShift documentation and the Red Hat
blog:</p>
<ul>
<li><a href="https://docs.openshift.com/container-platform/4.9/operators/understanding/olm/olm-understanding-olm.html">&ldquo;Operator Lifecycle Manager (OLM) concepts and resources&rdquo;</a></li>
<li><a href="https://docs.openshift.com/container-platform/4.9/authentication/understanding-authentication.html">&ldquo;Understanding authentication&rdquo;</a></li>
<li><a href="https://docs.openshift.com/container-platform/4.9/authentication/using-rbac.html">&ldquo;Role-based access control (RBAC)&rdquo;</a>,
covering rules, roles and bindings for authorization, as well as cluster RBAC vs local RBAC through projects</li>
<li><a href="https://docs.openshift.com/container-platform/4.9/authentication/using-service-accounts-in-applications.html#default-service-accounts-and-roles_using-service-accounts">&ldquo;Default project service accounts and roles&rdquo;</a></li>
<li><a href="https://www.redhat.com/en/blog/kubernetes-operators-comes-great-responsibility">&ldquo;With Kubernetes Operators comes great responsibility&rdquo; blog article</a></li>
</ul>
<h3 id="cluster-service-version-csv">Cluster Service Version (CSV)</h3>
<p>Technically, the operator is designed to run in OpenShift via the Operator
Lifecycle Manager (OLM), according to the Cluster Service Version (CSV) defined
by EDB.</p>
<p>The CSV is a YAML manifest that defines not only the user interfaces (available
through the web dashboard), but also the RBAC rules required by the operator
and the custom resources defined and owned by the operator (such as the
<code>Cluster</code> one, for example). The CSV defines also the available <code>installModes</code>
for the operator, namely: <code>AllNamespaces</code> (cluster-wide), <code>SingleNamespace</code>
(single project), <code>MultiNamespace</code> (multi-project), and <code>OwnNamespace</code>.</p>
<p>!!! Seealso &ldquo;There&rsquo;s more &hellip;&rdquo;
You can find out more about CSVs and install modes by reading
<a href="https://docs.openshift.com/container-platform/4.9/operators/understanding/olm/olm-understanding-operatorgroups.html#olm-operatorgroups-membership_olm-understanding-operatorgroups">&ldquo;Operator group membership&rdquo;</a>
and <a href="https://docs.openshift.com/container-platform/4.9/operators/operator_sdk/osdk-generating-csvs.html">&ldquo;Defining cluster service versions (CSVs)&rdquo;</a>
from the OpenShift documentation.</p>
<h3 id="limitations-for-multi-tenant-management">Limitations for multi-tenant management</h3>
<p>Red Hat OpenShift Container Platform provides limited support for
simultaneously installing different variations of an operator on a single
cluster. Like any other operator, Cloud Native PostgreSQL becomes an extension
of the control plane. As the control plane is shared among all tenants
(projects) of an OpenShift cluster, operators too become shared resources in a
multi-tenant environment.</p>
<p>Operator Lifecycle Manager (OLM) can install operators multiple times in
different namespaces, with one important limitation: they all need to share the
same API version of the operator.</p>
<p>For more information, please refer to
<a href="https://docs.openshift.com/container-platform/4.9/operators/understanding/olm/olm-understanding-operatorgroups.html">&ldquo;Operator groups&rdquo;</a>
in OpenShift documentation.</p>
<h2 id="installation-via-web-console">Installation via web console</h2>
<p>The Cloud Native PostgreSQL operator can be found in the Red Hat OperatorHub
directly from your OpenShift dashboard.</p>
<ol>
<li>
<p>Navigate in the web console to the <code>Operators -&gt; OperatorHub</code> page:</p>
<p><img src="./images/openshift/operatorhub_1.png" alt="Menu OperatorHub"></p>
</li>
<li>
<p>Scroll in the <code>Database</code> section or type a keyword into the <code>Filter by keyword</code>
box (in this case, &ldquo;PostgreSQL&rdquo;) to find the Cloud Native PostgreSQL
Operator, then select it:</p>
<p><img src="./images/openshift/operatorhub_2.png" alt="Install OperatorHub"></p>
</li>
<li>
<p>Read the information about the Operator and select <code>Install</code>.</p>
</li>
<li>
<p>The following <code>Operator installation</code> page expects you to choose:</p>
<ul>
<li>the installation mode: <a href="#cluster-wide-installation">cluster-wide</a> or
<a href="#single-project-installation">single namespace</a> installation</li>
<li>the update channel: currently only stable is available</li>
<li>the approval strategy, following the availability on the market place of
a new release of the operator, certified by Red Hat:</li>
<li><code>Automatic</code>: OLM automatically upgrades the running operator with the
new version</li>
<li><code>Manual</code>:  OpenShift waits for human intervention, by requiring an
approval in the <code>Installed Operators</code> section</li>
</ul>
<p>!!! Important
The process of the operator upgrade is described in the
<a href="installation_upgrade.md#upgrades">&ldquo;Upgrades&rdquo; section</a>.</p>
</li>
</ol>
<p>!!! Important
It is possible to install the operator in a single project
(technically speaking: <code>OwnNamespace</code> install mode) multiple times
in the same cluster. There will be an operator installation in every namespace,
with different upgrade policies as long as the API is the same (see
<a href="#limitations-for-multi-tenant-management">&ldquo;Limitations for multi-tenant management&rdquo;</a>).</p>
<p>Choosing cluster-wide vs local installation of the operator is a critical
turning point. Trying to install the operator globally with an existing local
installation is blocked, by throwing the error below. If you want to proceed
you need to remove every local installation of the operator first.</p>
<p><img src="./images/openshift/openshift-operatorgroup-error.png" alt="Install failing"></p>
<h3 id="cluster-wide-installation">Cluster-wide installation</h3>
<p>With cluster-wide installation, you are asking OpenShift to install the
Operator in the default <code>openshift-operators</code> namespace and to make it
available to all the projects in the cluster. This is the default and normally
recommended approach to install Cloud Native PostgreSQL.</p>
<p>!!! Warning
This doesn&rsquo;t mean that every user in the OpenShift cluster can use the Cloud Native
PostgreSQL Operator, deploy a <code>Cluster</code> object or even see the <code>Cluster</code> objects that
are running in their own namespaces. There are some special roles that users must
have in the namespace in order to interact with Cloud Native PostgreSQL&rsquo;s managed
custom resources - primarily the <code>Cluster</code> one. Please refer to the
<a href="#users-and-permissions">&ldquo;Users and Permissions&rdquo; section below</a> for details.</p>
<p>From the web console, select <code>All namespaces on the cluster (default)</code> as
<code>Installation mode</code>:</p>
<p><img src="./images/openshift/openshift-webconsole-allnamespaces.png" alt="Install all namespaces"></p>
<p>As a result, the operator will be visible in every namespaces. Otherwise, as with any
other OpenShift operator, check the logs in any pods in the <code>openshift-operators</code>
project on the <code>Workloads → Pods</code> page that are reporting issues to troubleshoot further.</p>
<p>!!! Important &ldquo;Beware&rdquo;
By choosing the cluster-wide installation you cannot easily move to a
single project installation at a later time.</p>
<h3 id="single-project-installation">Single project installation</h3>
<p>With single project installation, you are asking OpenShift to install the
Operator in a given namespace, and to make it available to that project only.</p>
<p>!!! Warning
This doesn&rsquo;t mean that every user in the namespace can use the Cloud Native
PostgreSQL Operator, deploy a <code>Cluster</code> object or even see the <code>Cluster</code> objects that
are running in the namespace. Similarly to the cluster-wide installation mode,
There are some special roles that users must have in the namespace in order to
interact with Cloud Native PostgreSQL&rsquo;s managed custom resources - primarily the <code>Cluster</code>
one. Please refer to the <a href="#users-and-permissions">&ldquo;Users and Permissions&rdquo; section below</a>
for details.</p>
<p>From the web console, select <code>A specific namespace on the cluster</code> as
<code>Installation mode</code>, then pick the target namespace (in our example
<code>proj-dev</code>):</p>
<p><img src="./images/openshift/openshift-webconsole-singlenamespace.png" alt="Install one namespace"></p>
<p>As a result, the operator will be visible in the selected namespace only. You
can verify this from the <code>Installed operators</code> page:</p>
<p><img src="./images/openshift/openshift-webconsole-singlenamespace-list.png" alt="Install one namespace list"></p>
<p>In case of a problem, from the <code>Workloads → Pods</code> page check the logs in any
pods in the selected installation namespace that are reporting issues to
troubleshoot further.</p>
<p>!!! Important &ldquo;Beware&rdquo;
By choosing the single project installation you cannot easily move to a
cluster-wide installation at a later time.</p>
<p>This installation process can be repeated in multiple namespaces in the same
OpenShift cluster, enabling independent installations of the operator in
different projects. In this case, make sure you read
<a href="#limitations-for-multi-tenant-management">&ldquo;Limitations for multi-tenant management&rdquo;</a>.</p>
<h2 id="installation-via-the-oc-cli">Installation via the <code>oc</code> CLI</h2>
<p>!!! Important
Please refer to the <a href="#installing-the-openshift-cli-oc">&ldquo;Installing the OpenShift CLI&rdquo; section below</a>
for information on how to install the <code>oc</code> command-line interface.</p>
<p>Instead of using the OpenShift Container Platform web console, you can install
the Cloud Native PostgreSQL Operator from the OperatorHub and create a
subscription using the <code>oc</code> command-line interface. Through the <code>oc</code> CLI you
can install the operator in all namespaces, a single namespace or multiple
namespaces.</p>
<p>!!! Warning
Multiple namespace installation is currently supported by OpenShift.
However, <a href="https://docs.openshift.com/container-platform/4.9/operators/understanding/olm/olm-understanding-operatorgroups.html#olm-operatorgroups-target-namespace_olm-understanding-operatorgroups">definition of multiple target namespaces for an operator may be removed in future versions of OpenShift</a>.</p>
<p>This section primarily covers the installation of the operator in multiple
projects with a simple example, by creating an <code>OperatorGroup</code> and a
<code>Subscription</code> objects.</p>
<p>!!! Info
In our example, we will install the operator in the <code>my-operators</code>
namespace and make it only available in the <code>web-staging</code>, <code>web-prod</code>,
<code>bi-staging</code>, and <code>bi-prod</code> namespaces. Feel free to change the names of the
projects as you like or add/remove some namespaces.</p>
<ol>
<li>
<p>Check that the <code>cloud-native-postgresql</code> operator is available from the
OperatorHub:</p>
<pre><code> oc get packagemanifests -n openshift-marketplace cloud-native-postgresql
</code></pre>
</li>
<li>
<p>Inspect the operator to verify the installation modes (<code>MultiNamespace</code> in
particular) and the available channels:</p>
<pre><code> oc describe packagemanifests -n openshift-marketplace cloud-native-postgresql
</code></pre>
</li>
<li>
<p>Create an <code>OperatorGroup</code> object in the <code>my-operators</code> namespace so that it
targets the <code>web-staging</code>, <code>web-prod</code>, <code>bi-staging</code>, and <code>bi-prod</code> namespaces:</p>
<pre><code> apiVersion: operators.coreos.com/v1
 kind: OperatorGroup
 metadata:
   name: cloud-native-postgresql
   namespace: my-operators
 spec:
   targetNamespaces:
   - web-staging
   - web-prod
   - bi-staging
   - bi-prod
</code></pre>
<p>!!! Important
Alternatively, you can list namespaces using a label selector, as explained in
<a href="https://docs.openshift.com/container-platform/4.9/operators/understanding/olm/olm-understanding-operatorgroups.html#olm-operatorgroups-target-namespace_olm-understanding-operatorgroups">&ldquo;Target namespace selection&rdquo;</a>.</p>
</li>
<li>
<p>Create a <code>Subscription</code> object in the <code>my-operators</code> namespace to subscribe
to the <code>stable</code> channel of the <code>cloud-native-postgresql</code> operator that is
available in the <code>certified-operators</code> source of the <code>openshift-marketplace</code>
(as previously located in steps 1 and 2):</p>
<pre><code> apiVersion: operators.coreos.com/v1alpha1
 kind: Subscription
 metadata:
   name: cloud-native-postgresql
   namespace: my-operators
 spec:
   channel: stable
   name: cloud-native-postgresql
   source: certified-operators
   sourceNamespace: openshift-marketplace
</code></pre>
</li>
<li>
<p>Use <code>oc apply -f</code> with the above YAML file definitions for the
<code>OperatorGroup</code> and <code>Subscription</code> objects.</p>
</li>
</ol>
<p>The method described in this section can be very powerful in conjunction with
proper <code>RoleBinding</code> objects, as it enables mapping Cloud Native PostgreSQL&rsquo;s
predefined <code>ClusterRole</code>s to specific users in selected namespaces.</p>
<p>!!! Info
The above instructions can also be used for single project binding. The
only difference is the number of specified target namespaces (one) and,
possibly, the namespace of the operator group (ideally, the same as the target
namespace).</p>
<p>The result of the above operation can also be verified from the webconsole, as
shown in the image below.</p>
<p><img src="./images/openshift/openshift-webconsole-multinamespace.png" alt="Multi namespace installation displayed in the web console"></p>
<h3 id="cluster-wide-installation-with-oc">Cluster-wide installation with <code>oc</code></h3>
<p>If you prefer, you can also use <code>oc</code> to install the operator globally, by
taking advantage of the default <code>OperatorGroup</code> called <code>global-operators</code> in
the <code>openshift-operators</code> namespace, and create a new <code>Subscription</code> object for
the <code>cloud-native-postgresql</code> operator in the same namespace:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">operators.coreos.com/v1alpha1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Subscription</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cloud-native-postgresql</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">openshift-operators</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">channel</span>: <span style="color:#ae81ff">stable</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">cloud-native-postgresql</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">source</span>: <span style="color:#ae81ff">certified-operators</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sourceNamespace</span>: <span style="color:#ae81ff">openshift-marketplace</span>
</span></span></code></pre></div><p>Once you run <code>oc apply -f</code> with the above YAML file, the operator will be available in all namespaces.</p>
<h3 id="installing-the-openshift-cli-oc">Installing the OpenShift CLI (<code>oc</code>)</h3>
<p>The <code>oc</code> command represents the OpenShift command-line interface (CLI). It is
highly recommended to install it on your system. Below you find a basic set of
instructions to install <code>oc</code> from your OpenShift dashboard.</p>
<p>First, select the question mark at the top right corner of the dashboard:</p>
<p><img src="./images/openshift/oc_installation_screenshot_1.png" alt="Command Line Tools menu"></p>
<p>Then follow the instructions you are given, by downloading the binary that
suits your needs in terms of operating system and architecture:</p>
<p><img src="./images/openshift/oc_installation_screenshot_2.png" alt="Command Line Tools"></p>
<p>!!! Seealso &ldquo;OpenShift CLI&rdquo;
For more detailed and updated information, please refer to the official
<a href="https://docs.openshift.com/container-platform/4.9/cli_reference/openshift_cli/getting-started-cli.html">OpenShift CLI documentation</a>
directly maintained by Red Hat.</p>
<h2 id="predefined-rbac-objects">Predefined RBAC objects</h2>
<p>Cloud Native PostgreSQL comes with a predefined set of resources that play an
important role when it comes to RBAC policy configuration.</p>
<h3 id="custom-resource-definitions-crd">Custom Resource Definitions (CRD)</h3>
<p>The Cloud Native PostgreSQL operator owns the following custom resource
definitions (CRD):</p>
<ul>
<li><code>Backup</code></li>
<li><code>Cluster</code></li>
<li><code>Pooler</code></li>
<li><code>ScheduledBackup</code></li>
</ul>
<p>You can verify this by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>oc get customresourcedefinitions.apiextensions.k8s.io | grep postgresql
</span></span></code></pre></div><p>which returns something similar to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>backups.postgresql.k8s.enterprisedb.io                            20YY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>clusters.postgresql.k8s.enterprisedb.io                           20YY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>poolers.postgresql.k8s.enterprisedb.io                            20YY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>scheduledbackups.postgresql.k8s.enterprisedb.io                   20YY-MM-DDTHH:MM:SSZ
</span></span></code></pre></div><h3 id="service-accounts">Service accounts</h3>
<p>The namespace where the operator has been installed (by default
<code>openshift-operators</code>) contains the following predefined service accounts:
<code>builder</code>, <code>default</code>, <code>deployer</code>, and most importantly
<code>postgresql-operator-manager</code> (managed by the CSV).</p>
<p>!!! Important
Service accounts in Kubernetes are namespaced resources. Unless explicitly
authorized, a service account cannot be accessed outside the defined namespace.</p>
<p>You can verify this by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>oc get serviceaccounts -n openshift-operators
</span></span></code></pre></div><p>which returns something similar to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>NAME                          SECRETS   AGE
</span></span><span style="display:flex;"><span>builder                       2         ...
</span></span><span style="display:flex;"><span>default                       2         ...
</span></span><span style="display:flex;"><span>deployer                      2         ...
</span></span><span style="display:flex;"><span>postgresql-operator-manager   2         ...
</span></span></code></pre></div><p>The <code>default</code> service account is automatically created by Kubernetes and
present in every namespace. The <code>builder</code> and <code>deployer</code> service accounts are
automatically created by OpenShift (see <a href="https://docs.openshift.com/container-platform/4.9/authentication/using-service-accounts-in-applications.html#default-service-accounts-and-roles_using-service-accounts">&ldquo;Default project service accounts and roles&rdquo;</a>).</p>
<p>The <code>postgresql-operator-manager</code> service account is the one used by the Cloud
Native PostgreSQL operator to work as part of the Kubernetes/OpenShift control
plane in managing PostgreSQL clusters.</p>
<p>!!! Important
Do not delete the <code>postgresql-operator-manager</code> ServiceAccount as it can
stop the operator from working.</p>
<h3 id="cluster-roles">Cluster roles</h3>
<p>The Operator Licecycle Manager (OLM) automatically creates a set of cluster
role objects to facilitate role binding definitions and granular implementation
of RBAC policies. Some cluster roles have rules that apply to Custom Resource
Definitions that are part of Cloud Native PostgreSQL, while others that are
part of the broader Kubernetes/OpenShift realm.</p>
<h4 id="cluster-roles-on-cloud-native-postgresql-crds">Cluster roles on Cloud Native PostgreSQL CRDs</h4>
<p>For <a href="#custom-resource-definitions-crd">every CRD owned by Cloud Native PostgreSQL&rsquo;s CSV</a>,
OLM deploys some predefined cluster roles that can be used by customer facing
users and service accounts. In particular:</p>
<ul>
<li>a role for the full administration of the resource (<code>admin</code> suffix)</li>
<li>a role to edit the resource (<code>edit</code> suffix)</li>
<li>a role to view the resource (<code>view</code> suffix)</li>
<li>a role to view the actual CRD (<code>crdview</code> suffix)</li>
</ul>
<p>!!! Important
Cluster roles per se are no security threat. They are the recommended way
in OpenShift to define templates for roles to be later &ldquo;bound&rdquo; to actual users
in a specific project or globally. Indeed, cluster roles can be used in
conjunction with <code>ClusterRoleBinding</code> objects for global permissions or with
<code>RoleBinding</code> objects for local permissions. This makes it possible to reuse
cluster roles across multiple projects while enabling customization within
individual projects through local roles.</p>
<p>You can verify the list of predefined cluster roles by running:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>oc get clusterroles | grep postgresql
</span></span></code></pre></div><p>which returns something similar to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>backups.postgresql.k8s.enterprisedb.io-v1-admin                  YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>backups.postgresql.k8s.enterprisedb.io-v1-crdview                YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>backups.postgresql.k8s.enterprisedb.io-v1-edit                   YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>backups.postgresql.k8s.enterprisedb.io-v1-view                   YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>cloud-native-postgresql.VERSION-HASH                             YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>clusters.postgresql.k8s.enterprisedb.io-v1-admin                 YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>clusters.postgresql.k8s.enterprisedb.io-v1-crdview               YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>clusters.postgresql.k8s.enterprisedb.io-v1-edit                  YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>clusters.postgresql.k8s.enterprisedb.io-v1-view                  YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>poolers.postgresql.k8s.enterprisedb.io-v1-admin                  YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>poolers.postgresql.k8s.enterprisedb.io-v1-crdview                YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>poolers.postgresql.k8s.enterprisedb.io-v1-edit                   YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>poolers.postgresql.k8s.enterprisedb.io-v1-view                   YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>scheduledbackups.postgresql.k8s.enterprisedb.io-v1-admin         YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>scheduledbackups.postgresql.k8s.enterprisedb.io-v1-crdview       YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>scheduledbackups.postgresql.k8s.enterprisedb.io-v1-edit          YYYY-MM-DDTHH:MM:SSZ
</span></span><span style="display:flex;"><span>scheduledbackups.postgresql.k8s.enterprisedb.io-v1-view          YYYY-MM-DDTHH:MM:SSZ
</span></span></code></pre></div><p>You can inspect an actual role as any other Kubernetes resource with the <code>get</code>
command. For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>oc get -o yaml clusterrole clusters.postgresql.k8s.enterprisedb.io-v1-admin
</span></span></code></pre></div><p>By looking at the relevant skimmed output below, you can notice that the
<code>clusters.postgresql.k8s.enterprisedb.io-v1-admin</code> cluster role enables
everything on the <code>cluster</code> resource defined by the
<code>postgresql.k8s.enterprisedb.io</code> API group:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">clusters.postgresql.k8s.enterprisedb.io-v1-admin</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">postgresql.k8s.enterprisedb.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">clusters</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;*&#39;</span>
</span></span></code></pre></div><p>!!! Seealso &ldquo;There&rsquo;s more &hellip;&rdquo;
If you are interested in the actual implementation of RBAC by an
OperatorGroup, please refer to the
<a href="https://olm.operatorframework.io/docs/concepts/crds/operatorgroup/#rbac">&ldquo;OperatorGroup: RBAC&rdquo; section from the Operator Lifecycle Manager documentation</a>.</p>
<h4 id="cluster-roles-on-kubernetes-crds">Cluster roles on Kubernetes CRDs</h4>
<p>When installing a <code>Subscription</code> object in a given namespace (e.g.
<code>openshift-operators</code> for cluster-wide installation of the operator), OLM also
creates a cluster role that is used to grant permissions to the
<code>postgresql-operator-manager</code> service account that the operator uses. The name
of this cluster role varies, as it depends on the installed version of the
operator and the time of installation.</p>
<p>You can retrieve it by running the following command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>oc get clusterrole --selector<span style="color:#f92672">=</span>olm.owner.kind<span style="color:#f92672">=</span>ClusterServiceVersion
</span></span></code></pre></div><p>You can then use the name returned by the above query (which should have the
form of <code>cloud-native-postgresql.VERSION-HASH</code>) to look at the rules, resources
and verbs via the <code>describe</code> command:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>oc describe clusterrole cloud-native-postgresql.VERSION-HASH
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-console" data-lang="console"><span style="display:flex;"><span>Name:         cloud-native-postgresql.VERSION.HASH
</span></span><span style="display:flex;"><span>Labels:       olm.owner=cloud-native-postgresql.VERSION
</span></span><span style="display:flex;"><span>              olm.owner.kind=ClusterServiceVersion
</span></span><span style="display:flex;"><span>              olm.owner.namespace=openshift-operators
</span></span><span style="display:flex;"><span>              operators.coreos.com/cloud-native-postgresql.openshift-operators=
</span></span><span style="display:flex;"><span>Annotations:  &lt;none&gt;
</span></span><span style="display:flex;"><span>PolicyRule:
</span></span><span style="display:flex;"><span>  Resources                                                     Non-Resource URLs  Resource Names  Verbs
</span></span><span style="display:flex;"><span>  ---------                                                     -----------------  --------------  -----
</span></span><span style="display:flex;"><span>  configmaps                                                    []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  secrets                                                       []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  services                                                      []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  deployments.apps                                              []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  poddisruptionbudgets.policy                                   []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  backups.postgresql.k8s.enterprisedb.io                        []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  clusters.postgresql.k8s.enterprisedb.io                       []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  poolers.postgresql.k8s.enterprisedb.io                        []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  scheduledbackups.postgresql.k8s.enterprisedb.io               []                 []              [create delete get list patch update watch]
</span></span><span style="display:flex;"><span>  persistentvolumeclaims                                        []                 []              [create delete get list patch watch]
</span></span><span style="display:flex;"><span>  pods/exec                                                     []                 []              [create delete get list patch watch]
</span></span><span style="display:flex;"><span>  pods                                                          []                 []              [create delete get list patch watch]
</span></span><span style="display:flex;"><span>  jobs.batch                                                    []                 []              [create delete get list patch watch]
</span></span><span style="display:flex;"><span>  podmonitors.monitoring.coreos.com                             []                 []              [create delete get list patch watch]
</span></span><span style="display:flex;"><span>  serviceaccounts                                               []                 []              [create get list patch update watch]
</span></span><span style="display:flex;"><span>  rolebindings.rbac.authorization.k8s.io                        []                 []              [create get list patch update watch]
</span></span><span style="display:flex;"><span>  roles.rbac.authorization.k8s.io                               []                 []              [create get list patch update watch]
</span></span><span style="display:flex;"><span>  leases.coordination.k8s.io                                    []                 []              [create get update]
</span></span><span style="display:flex;"><span>  events                                                        []                 []              [create patch]
</span></span><span style="display:flex;"><span>  mutatingwebhookconfigurations.admissionregistration.k8s.io    []                 []              [get list update]
</span></span><span style="display:flex;"><span>  validatingwebhookconfigurations.admissionregistration.k8s.io  []                 []              [get list update]
</span></span><span style="display:flex;"><span>  customresourcedefinitions.apiextensions.k8s.io                []                 []              [get list update]
</span></span><span style="display:flex;"><span>  namespaces                                                    []                 []              [get list watch]
</span></span><span style="display:flex;"><span>  nodes                                                         []                 []              [get list watch]
</span></span><span style="display:flex;"><span>  clusters.postgresql.k8s.enterprisedb.io/status                []                 []              [get patch update watch]
</span></span><span style="display:flex;"><span>  poolers.postgresql.k8s.enterprisedb.io/status                 []                 []              [get patch update watch]
</span></span><span style="display:flex;"><span>  configmaps/status                                             []                 []              [get patch update]
</span></span><span style="display:flex;"><span>  secrets/status                                                []                 []              [get patch update]
</span></span><span style="display:flex;"><span>  backups.postgresql.k8s.enterprisedb.io/status                 []                 []              [get patch update]
</span></span><span style="display:flex;"><span>  scheduledbackups.postgresql.k8s.enterprisedb.io/status        []                 []              [get patch update]
</span></span><span style="display:flex;"><span>  pods/status                                                   []                 []              [get]
</span></span><span style="display:flex;"><span>  clusters.postgresql.k8s.enterprisedb.io/finalizers            []                 []              [update]
</span></span><span style="display:flex;"><span>  poolers.postgresql.k8s.enterprisedb.io/finalizers             []                 []              [update]
</span></span></code></pre></div><p>!!! Important
The above permissions are exclusively reserved for the operator&rsquo;s service
account to interact with the Kubernetes API server.  They are not directly
accessible by the users of the operator that interact only with <code>Cluster</code>,
<code>Pooler</code>, <code>Backup</code>, and <code>ScheduledBackup</code> resources (see
<a href="#cluster-roles-on-cloud-native-postgresql-crds">&ldquo;Cluster roles on Cloud Native PostgreSQL CRDs&rdquo;</a>).</p>
<p>The operator automates in a declarative way a lot of operations related to
PostgreSQL management that otherwise would require manual and imperative
interventions. Such operations also include security related matters at RBAC
(e.g. service accounts), pod (e.g. security context constraints) and Postgres
levels (e.g. TLS certificates).</p>
<p>For more information about the reasons why the operator needs these elevated
permissions, please refer to the
<a href="security.md#role-based-access-control-rbac">&ldquo;Security / Cluster / RBAC&rdquo; section</a>.</p>
<h2 id="users-and-permissions">Users and Permissions</h2>
<p>A very common way to use the Cloud Native PostgreSQL operator is to rely on the
<code>cluster-admin</code> role and manage resources centrally.</p>
<p>Alternatively, you can use the RBAC framework made available by
Kubernetes/OpenShift, as with any other operator or resources.</p>
<p>For example, you might be interested in binding the
<code>clusters.postgresql.k8s.enterprisedb.io-v1-admin</code> cluster role to specific
groups or users in a specific namespace, as any other cloud native application.
The following example binds that cluster role to a specific user in the
<code>web-prod</code> project:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">web-prod-admin</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">web-prod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">User</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mario@cioni.org</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterRole</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">clusters.postgresql.k8s.enterprisedb.io-v1-admin</span>
</span></span></code></pre></div><p>The same process can be repeated with any other predefined <code>ClusterRole</code>.</p>
<p>If, on the other hand, you prefer not to use cluster roles, you can create
specific namespaced roles like in this example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">web-prod-view</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">web-prod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">postgresql.k8s.enterprisedb.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">clusters</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">get</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">list</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">watch</span>
</span></span></code></pre></div><p>Then, assign this role to a given user:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">RoleBinding</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">web-prod-view</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">web-prod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">roleRef</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">web-prod-view</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">subjects</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroup</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">kind</span>: <span style="color:#ae81ff">User</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">web-prod-developer1</span>
</span></span></code></pre></div><p>This final example creates a role with administration permissions (<code>verbs</code> is
equal to <code>*</code>) to all the resources managed by the operator in that namespace
(<code>web-prod</code>):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">rbac.authorization.k8s.io/v1</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Role</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">metadata</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">web-prod-admin</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">web-prod</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">rules</span>:
</span></span><span style="display:flex;"><span>- <span style="color:#f92672">apiGroups</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">postgresql.k8s.enterprisedb.io</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">resources</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">clusters</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">backups</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">scheduledbackups</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">poolers</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">verbs</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#e6db74">&#39;*&#39;</span>
</span></span></code></pre></div>


    <footer class="text-center p-24">
    <div>
        <a href="#" class="bg-rose-600 py-4 px-12 rounded-full text-white text-xl">View on GitHub</a>
    </div>
    <p class="text-sm text-slate-600 w-1/2 mx-auto pt-10">&copy; 2019-2022 The CloudNativePG Contributors<br/>
    The Linux Foundation has registered trademarks and uses trademarks. 
    For a list of trademarks of The Linux Foundation, please see our <a href="https://www.linuxfoundation.org/trademark-usage/" class="text-rose-600">Trademark Usage page</a>.<br/>
    Postgres, PostgreSQL and the Slonik Logo are trademarks or registered trademarks of the PostgreSQL Community Association of Canada, and used with their permission.
    </p>
</footer>

  </div>
  
  <script src="https://cdn.usefathom.com/script.js" data-site="GSMQCVAJ" defer></script>
  
</body>

</html>